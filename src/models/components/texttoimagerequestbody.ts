/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod";
import { remap as remap$ } from "../../lib/primitives.js";
import { safeParse } from "../../lib/schemas.js";
import { Result as SafeParseResult } from "../../types/fp.js";
import { SDKValidationError } from "../errors/sdkvalidationerror.js";
import {
  ClipGuidancePreset,
  ClipGuidancePreset$inboundSchema,
  ClipGuidancePreset$outboundSchema,
} from "./clipguidancepreset.js";
import {
  Extras,
  Extras$inboundSchema,
  Extras$Outbound,
  Extras$outboundSchema,
} from "./extras.js";
import {
  Sampler,
  Sampler$inboundSchema,
  Sampler$outboundSchema,
} from "./sampler.js";
import {
  StylePreset,
  StylePreset$inboundSchema,
  StylePreset$outboundSchema,
} from "./stylepreset.js";
import {
  TextPrompt,
  TextPrompt$inboundSchema,
  TextPrompt$Outbound,
  TextPrompt$outboundSchema,
} from "./textprompt.js";

/**
 * Represents the optional parameters that can be passed to any generation request.
 */
export type TextToImageRequestBody = {
  /**
   * Height of the image to generate, in pixels, in an increment divisible by 64.
   */
  height?: number | undefined;
  /**
   * Width of the image to generate, in pixels, in an increment divisible by 64.
   */
  width?: number | undefined;
  /**
   * An array of text prompts to use for generation.
   *
   * @remarks
   *
   * Given a text prompt with the text `A lighthouse on a cliff` and a weight of `0.5`, it would be represented as:
   *
   * ```
   * "text_prompts": [
   *   {
   *     "text": "A lighthouse on a cliff",
   *     "weight": 0.5
   *   }
   * ]
   * ```
   */
  textPrompts: Array<TextPrompt>;
  /**
   * How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)
   */
  cfgScale?: number | undefined;
  clipGuidancePreset?: ClipGuidancePreset | undefined;
  /**
   * Which sampler to use for the diffusion process. If this value is omitted we'll automatically select an appropriate sampler for you.
   */
  sampler?: Sampler | undefined;
  /**
   * Number of images to generate
   */
  samples?: number | undefined;
  /**
   * Random noise seed (omit this option or use `0` for a random seed)
   */
  seed?: number | undefined;
  /**
   * Number of diffusion steps to run.
   */
  steps?: number | undefined;
  /**
   * Pass in a style preset to guide the image model towards a particular style.
   *
   * @remarks
   * This list of style presets is subject to change.
   */
  stylePreset?: StylePreset | undefined;
  /**
   * Extra parameters passed to the engine.
   *
   * @remarks
   * These parameters are used for in-development or experimental features and may change
   * without warning, so please use with caution.
   */
  extras?: Extras | undefined;
};

/** @internal */
export const TextToImageRequestBody$inboundSchema: z.ZodType<
  TextToImageRequestBody,
  z.ZodTypeDef,
  unknown
> = z.object({
  height: z.number().int().default(512),
  width: z.number().int().default(512),
  text_prompts: z.array(TextPrompt$inboundSchema),
  cfg_scale: z.number().default(7),
  clip_guidance_preset: ClipGuidancePreset$inboundSchema.default("NONE"),
  sampler: Sampler$inboundSchema.optional(),
  samples: z.number().int().default(1),
  seed: z.number().int().default(0),
  steps: z.number().int().default(30),
  style_preset: StylePreset$inboundSchema.optional(),
  extras: Extras$inboundSchema.optional(),
}).transform((v) => {
  return remap$(v, {
    "text_prompts": "textPrompts",
    "cfg_scale": "cfgScale",
    "clip_guidance_preset": "clipGuidancePreset",
    "style_preset": "stylePreset",
  });
});

/** @internal */
export type TextToImageRequestBody$Outbound = {
  height: number;
  width: number;
  text_prompts: Array<TextPrompt$Outbound>;
  cfg_scale: number;
  clip_guidance_preset: string;
  sampler?: string | undefined;
  samples: number;
  seed: number;
  steps: number;
  style_preset?: string | undefined;
  extras?: Extras$Outbound | undefined;
};

/** @internal */
export const TextToImageRequestBody$outboundSchema: z.ZodType<
  TextToImageRequestBody$Outbound,
  z.ZodTypeDef,
  TextToImageRequestBody
> = z.object({
  height: z.number().int().default(512),
  width: z.number().int().default(512),
  textPrompts: z.array(TextPrompt$outboundSchema),
  cfgScale: z.number().default(7),
  clipGuidancePreset: ClipGuidancePreset$outboundSchema.default("NONE"),
  sampler: Sampler$outboundSchema.optional(),
  samples: z.number().int().default(1),
  seed: z.number().int().default(0),
  steps: z.number().int().default(30),
  stylePreset: StylePreset$outboundSchema.optional(),
  extras: Extras$outboundSchema.optional(),
}).transform((v) => {
  return remap$(v, {
    textPrompts: "text_prompts",
    cfgScale: "cfg_scale",
    clipGuidancePreset: "clip_guidance_preset",
    stylePreset: "style_preset",
  });
});

/**
 * @internal
 * @deprecated This namespace will be removed in future versions. Use schemas and types that are exported directly from this module.
 */
export namespace TextToImageRequestBody$ {
  /** @deprecated use `TextToImageRequestBody$inboundSchema` instead. */
  export const inboundSchema = TextToImageRequestBody$inboundSchema;
  /** @deprecated use `TextToImageRequestBody$outboundSchema` instead. */
  export const outboundSchema = TextToImageRequestBody$outboundSchema;
  /** @deprecated use `TextToImageRequestBody$Outbound` instead. */
  export type Outbound = TextToImageRequestBody$Outbound;
}

export function textToImageRequestBodyToJSON(
  textToImageRequestBody: TextToImageRequestBody,
): string {
  return JSON.stringify(
    TextToImageRequestBody$outboundSchema.parse(textToImageRequestBody),
  );
}

export function textToImageRequestBodyFromJSON(
  jsonString: string,
): SafeParseResult<TextToImageRequestBody, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TextToImageRequestBody$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TextToImageRequestBody' from JSON`,
  );
}
